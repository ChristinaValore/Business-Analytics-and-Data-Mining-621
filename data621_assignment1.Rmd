---
title: 'Assignment 1: Data 621'
author: "Critical Thinking Group 5 - Christina Valore, Henry Vasquez, Chunhui Zhu, Chunmei Zhu"
date: "9/16/2019"
output: html_document
---

```{r,message=F, warning=F}
library(tidyverse); library(dplyr); library(psych); library(corrplot); library (ggplot2); library(funModeling); library(Hmisc); library (car); library(caTools)
```

## Money Ball

In this homework assignment, you will explore, analyze and model a data set containing approximately 2200 records. Each record represents a professional baseball team from the years 1871 to 2006 inclusive. Each record has the performance of the team for the given year, with all of the statistics adjusted to match the performance of a 162 game season.

Your objective is to build a multiple linear regression model on the training data to predict the number of wins for the team. You can only use the variables given to you (or variables that you derive from the variables provided). Below is a short description of the variables of interest in the data set:

Response variable: Target_Wins
Predictor variable(s): Target_Wins = (team batting base hits + team batting walks) - (team pitching hits allowed + team pitching walks allowed)

### Data Analysis

First, we import data from our GitHub repo, then we remove any unnecessary columns such as 'index', which plays no role in our analysis. Once completed, we view the top of each dataset to ensure data was imported in the correct format.

```{r }
# import data
data <-read.csv("https://raw.githubusercontent.com/ChristinaValore/Business-Analytics-and-Data-Mining-621/master/moneyball-training-data.csv") 
eval <-read.csv("https://raw.githubusercontent.com/ChristinaValore/Business-Analytics-and-Data-Mining-621/master/moneyball-evaluation-data.csv") 

data <- select(data,-1) # remove index column, which is first column in both datasets
eval <- select(eval,-1)

head (data) # view data for both sets, notice the index column has been removed
head (eval)
```

We now will split the training data set into two sets: train_1 and test_1. The test_1 will help us validate our model. We will save the eval set to run predictions.
```{r}
set.seed(123)   #  set seed to ensure you always have same random numbers generated
sample <- sample.split(data,SplitRatio = 0.80) 
train_1 <- subset(data, sample ==TRUE) 
test_1 <- subset(data, sample==FALSE)

dim(train_1)
dim(test_1)
```

### Statistics

The summary function reveals there are a considerable amount of NA's and some variables have a min of 0, which can be possible in baseball, however a variable with too many zeros will be unuseful. Additonally some variables have max values that look far off from the 3rd quartile, i.e. team_batting_3B has the 3rd q at 72, while max is 223. These could be possible outliers.

```{r}
summary(train_1) # univariate view of basic stats
```


### Zeros and NA values

Using the df_status function from the funModeling package, we see that the quantity of zeros (q_zeros) is quite low for all variables. This can be confirmed by percentage of zeros (p_zeros) as all fall below 1%. 

The NA values seem to be more discerning as several of the variable have high percentage NA's. Specifically the values, baserun_CS and batting_HBP which has 33.92% and 91.61% NA's respectively. 

```{r}
#gives us information about 0's, NA's, variable type, and unique values
df_status(train_1)
```

These variables will need to be excluded from our analysis as we only want variables with less than 20% NA's. 

```{r}
train_1 <- subset(train_1, select = -c(TEAM_BASERUN_CS,TEAM_BATTING_HBP)) # drop both variable columns from dataframe
head(train_1) # check columns are removed
```


### Graphs

After some research, we decide to investigate the hits, walks and hits allowed and walks allowed as we think these four variables overall will have an impact on the wins.

By examining the scatter plots, we see that team batting base hits and team batting walks seem to have a linear relationship to wins as those variables increase it looks as if wins increase as well. 

Team pitching hits allowed and team pitching walks allowed, are not as clear and may not have a linear relationship to wins. They both also look to have more extreme ouliers as we saw in the summary. 

```{r}
par(mfrow = c(2,2)) #view graphs in 2x2 view

plot(TARGET_WINS ~ TEAM_BATTING_H,train_1) # batting hits

plot(TARGET_WINS ~ TEAM_BATTING_BB,train_1) # batting walks

plot(TARGET_WINS ~ TEAM_PITCHING_H,train_1) # pitching hits allowed

plot(TARGET_WINS ~ TEAM_PITCHING_BB,train_1) # pitching walks allowed

```

Batting_H and Batting_BB look to be the most normally distributed, where pitching_H and pitching_BB seem to be more concetrated to the left again indicating there may not be a linear relationship to target wins. 

```{r}

par(mfrow = c(2,2)) #view graphs in 2x2 view

hist(train_1$TEAM_BATTING_H) # hits 

hist(train_1$TEAM_BATTING_BB) # walks

hist(train_1$TEAM_PITCHING_H) # hits allowed

hist(train_1$TEAM_PITCHING_BB) #walks allowed

```

### Outliers

Since this will be a multi-variable regression, we want to consider how all four variables will affect the wins. This is done by using Cook's distance, which calculates the influence each point (row) has on the predicted outcome. 

```{r}
m <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_BB - (TEAM_PITCHING_H + TEAM_PITCHING_BB), data=train_1) # model with four variables considered

cook <- cooks.distance(m)

plot(cook, pch="*", cex=2, main="Cook's Distance: Influential Observations") # plot Cook's distance
abline(h = 4*mean(cook, na.rm=T), col="red") # add cutoff line, which is equivalent to 4*mean
text(x=1:length(cook)+1, y=cook, labels=ifelse(cook>4*mean(cook, na.rm=T),names(cook),""), col="red") # add labels for points (rows)
```

We can see the full view of the influential numbers by adding to a dataframe and viewing the head. We have 66 influential outliers. To take it one step further, we can find out what is the most influential outlier. 

```{r}
influential <- as.numeric(names(cook)[(cook > 4*mean(cook, na.rm=T))]) # add influential rows 

head(train_1[influential, ]) # show rows that match influential numbers
```

The most influential outlier is at row 1828. In the next section we will have to account how to handle the 89 outliers, including row 1828.

```{r}
outlierTest(m)
```

## Data Preparation

### Handling NA values

We impute the missing NA values with the mean using the Hmisc package:

```{r include=FALSE}
train_1$TEAM_BATTING_SO<-impute(train_1$TEAM_BATTING_SO, median)
train_1$TEAM_BASERUN_SB<-impute(train_1$TEAM_BASERUN_SB, median)
train_1$TEAM_PITCHING_SO<-impute(train_1$TEAM_PITCHING_SO, median)
train_1$TEAM_FIELDING_DP<-impute(train_1$TEAM_FIELDING_DP, median)
```


### Handling Outliers

We will have *TWO* train dataframes to compare which one performs better with our testing, one with outliers (train_1) and one with outliers removed (train_no):
```{r}
#removed outliers
train_no<-train_1[-influential, ]
```

### New variables

We create three variables:

team batting on base = team batting base hits + team batting walks
team pitching allows = team pitching hits allowed + team pitching walks allowed
BASE_DIFF = team batting on base - team pitching allows

Our thought is that the team that is on base more, will have a higher chance of winning.

```{r}

# with outliers
train_1$TEAM_BATTING_OB <- train_1$TEAM_BATTING_H + train_1$TEAM_BATTING_BB # create variable team batting on base
train_1$TEAM_PITCHING_A <- train_1$TEAM_PITCHING_H + train_1$TEAM_PITCHING_BB # create variable pitching allows
train_1$BASE_DIFF <- train_1$TEAM_BATTING_OB - train_1$TEAM_PITCHING_A #create variable base diff

# without outliers
train_no$TEAM_BATTING_OB <- train_no$TEAM_BATTING_H + train_no$TEAM_BATTING_BB # create variable team batting on base
train_no$TEAM_PITCHING_A <- train_no$TEAM_PITCHING_H + train_no$TEAM_PITCHING_BB # create variable pitching allows
train_no$BASE_DIFF <- train_no$TEAM_BATTING_OB - train_no$TEAM_PITCHING_A # create variable base diff
```


```{r}

par(mfrow = c(1,2)) #view graphs in 2x2 view
plot(train_1$BASE_DIFF,train_1$TARGET_WINS, xlab = "On plate difference", ylab = "Wins", title("Wins vs. On plate  difference"))

plot(train_no$BASE_DIFF,train_no$TARGET_WINS, xlab = "On plate difference", ylab = "Wins", title("Wins vs. On plate  difference"))

```

## Build Models

## Select Models

Sources: 

http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram

https://kharshit.github.io/blog/2017/07/28/moneyball-how-linear-regression-changed-baseball

https://towardsdatascience.com/linear-regression-moneyball-part-1-b93b3b9f5b53

http://r-statistics.co/Outlier-Treatment-With-R.html

https://blog.datascienceheroes.com/exploratory-data-analysis-in-r-intro/

